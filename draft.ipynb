{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import GraphConv\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.backend import gather, squeeze\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_in (InputLayer)               [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A_in (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn1 (GraphConv)                (None, 32)           320         X_in[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gcn2 (GraphConv)                (None, 32)           1056        gcn1[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "slice (Lambda)                  (1, None, 32)        0           gcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "squeeze (Lambda)                (None, 32)           0           slice[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "policy_1 (Dense)                (None, 32)           1056        squeeze[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "policy_2 (Dense)                (None, 16)           528         policy_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "RL_indice (InputLayer)          [(1, None)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "policy_3 (Dense)                (None, 3)            51          policy_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,011\n",
      "Trainable params: 3,011\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class GraphicEncoder():\n",
    "    def __init__(self, F):\n",
    "        self.model = self.build_model(F)\n",
    "\n",
    "    def build_model(self,F):\n",
    "        X_in = Input(shape=(F,), name='X_in')\n",
    "        A_in = Input(shape=(None,), name='A_in')\n",
    "        RL_indice = Input(shape=(None,),batch_size = 1, name='RL_indice',dtype='int32')\n",
    "\n",
    "        \n",
    "        ### Graphic convolution\n",
    "        \n",
    "        x = GraphConv(32, activation='relu',name='gcn1')([X_in, A_in])\n",
    "        x = GraphConv(32, activation='relu',name='gcn2')([x, A_in])\n",
    "        x = Lambda(lambda x: gather(x,RL_indice),name='slice')(x)\n",
    "        \n",
    "        x = Lambda(lambda x: squeeze(x,0),name='squeeze')(x)\n",
    "        \n",
    "        ### Policy network\n",
    "        \n",
    "        x = Dense(32,activation='relu',name='policy_1')(x)\n",
    "        x = Dense(16,activation='relu',name='policy_2')(x)\n",
    "        x = Dense(3, activation='relu',name='policy_3')(x)\n",
    "        \n",
    "        \n",
    "        model = Model(inputs = [X_in,A_in,RL_indice], outputs=x)\n",
    "        print(model.summary())\n",
    "        return model\n",
    "    \n",
    "    \n",
    "feature_size = 9\n",
    "rl_model = GraphicEncoder(feature_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces.box import Box\n",
    "from gym.spaces import Discrete\n",
    "from gym.spaces.dict import Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.models.tf.tf_modelv2 import TFModelV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 9\n",
    "N = 40\n",
    "\n",
    "states = Box(low=-np.inf, high=np.inf, shape=(N,F), dtype=np.float32)\n",
    "adjacency = Box(low=0, high=1, shape = (N,N), dtype=np.int32)\n",
    "mask = Box(low=0, high=1, shape = (N,), dtype=np.int32)\n",
    "\n",
    "obs_space = Dict({'states':states,'adjacency':adjacency,'mask':mask})\n",
    "act_space = Box(low=0, high=1, shape = (N,), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0522 12:43:45.736737 4542281152 deprecation.py:506] From /anaconda3/envs/flow/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_in (InputLayer)               [(None, 40, 9)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A_in (InputLayer)               [(None, 40, 40)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn1 (GraphConv)                (None, 40, 32)       320         X_in[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gcn2 (GraphConv)                (None, 40, 32)       1056        gcn1[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "policy_1 (Dense)                (None, 40, 32)       1056        gcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "policy_2 (Dense)                (None, 40, 16)       528         policy_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "policy_3 (Dense)                (None, 40, 3)        51          policy_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expend_dim (Reshape)            (None, 40, 1)        0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 640)          0           policy_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "filter (Multiply)               (None, 40, 3)        0           policy_3[0][0]                   \n",
      "                                                                 expend_dim[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "value_out (Dense)               (None, 1)            641         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,652\n",
      "Trainable params: 3,652\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from spektral.layers import GraphConv\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Multiply, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "class GraphicPolicy(TFModelV2):\n",
    "    def __init__(self, N,F, obs_space, action_space, num_outputs=3, model_config=None, name='graphic_policy'):\n",
    "        super(GraphicPolicy,self).__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "        self.base_model = self.build_model(N,F,num_outputs)\n",
    "        self.register_variables(self.base_model.variables)\n",
    "        \n",
    "    def build_model(self,N,F,num_outputs):\n",
    "        X_in = Input(shape=(N,F), name='X_in')\n",
    "        A_in = Input(shape=(N,N), name='A_in')\n",
    "        RL_indice = Input(shape=(N), name='mask')\n",
    "        \n",
    "        ### Graphic convolution\n",
    "        \n",
    "        x = GraphConv(32, activation='relu',name='gcn1')([X_in, A_in])\n",
    "        x = GraphConv(32, activation='relu',name='gcn2')([x, A_in])\n",
    "\n",
    "        \n",
    "        ### Policy network\n",
    "        \n",
    "        x1 = Dense(32,activation='relu',name='policy_1')(x)\n",
    "        x2 = Dense(16,activation='relu',name='policy_2')(x1)\n",
    "        \n",
    "    \n",
    "        ###  Action and filter\n",
    "        x3 = Dense(num_outputs, activation='relu',name='policy_3')(x2)\n",
    "        mask = Reshape((N,1),name='expend_dim')(RL_indice)\n",
    "        out = Multiply(name='filter')([x3,mask])\n",
    "        \n",
    "        \n",
    "        #### Value out\n",
    "        x2 = Flatten(name='flatten')(x2)\n",
    "        value = Dense(1,activation='linear',name='value_out')(x2)\n",
    "        \n",
    "\n",
    "        model = Model(inputs = [X_in,A_in,RL_indice], outputs=[out,value])\n",
    "        print(model.summary())\n",
    "        return model\n",
    "    \n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dic['obs']\n",
    "        model_out, self._value_out = self.base_model({X_in:obs['states'],A_in:obs['adjacency'],RL_indice:obs['mask']})        \n",
    "        return model_out,state\n",
    "        \n",
    "    def value_function(self):\n",
    "        return tf.reshape(self._value_out, [-1])\n",
    "    \n",
    "model_config = {}\n",
    "rl_model = GraphicPolicy(N,F, obs_space, act_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for the model + agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'action', 'reward', 'done'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2292"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['state'][300][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([7.9153743 , 9.26159146, 9.3487723 , 9.50259114, 9.26878305]),\n",
       "  array([[ 0.55876794, -1.29143597, -1.26157116,  0.0067175 ,  1.45762905],\n",
       "         [-0.2496225 , -1.18113194, -0.64023985,  0.57572564,  1.38913569],\n",
       "         [-0.36616133, -1.26427436, -1.58928474,  0.38834024,  0.86398796],\n",
       "         [-1.65986307, -0.75061176, -0.32146263, -0.20712333, -0.20888431],\n",
       "         [-0.95091533,  1.05943482, -0.57729136,  1.32082576, -1.13142716]]),\n",
       "  array([1., 1., 1., 1., 1.])],\n",
       " [array([20.10301795, 19.64728766, 19.78042387, 19.75255329, 18.50074277]),\n",
       "  array([[-0.94962712,  0.23880779, -0.47542062,  0.23625995, -1.07391709],\n",
       "         [ 0.53429654,  2.26011716,  0.08702358, -0.38375872, -0.68397557],\n",
       "         [-0.93602674,  1.1519039 , -0.32001743,  0.33319174, -0.18702573],\n",
       "         [ 0.43104547, -2.31832133,  0.95753109,  1.36804541,  0.44852518],\n",
       "         [ 0.18593171,  0.37139554, -1.65117117, -0.36697241,  0.84376992]]),\n",
       "  array([1., 1., 1., 1., 1.])],\n",
       " [array([30.11406164, 29.38965375, 29.54298764, 30.78447496, 29.61511207]),\n",
       "  array([[ 0.48386653,  1.04317504, -2.43577972,  0.36038324,  1.72185761],\n",
       "         [ 0.5009995 , -0.9515243 , -1.18458903,  1.52750326,  0.9615259 ],\n",
       "         [ 0.98332447,  0.86134298,  0.05788153,  0.55443295, -0.82889209],\n",
       "         [-0.47660449,  0.74807716, -1.52931238, -1.08776503, -1.1454656 ],\n",
       "         [ 0.89097664, -0.4014252 , -0.50615956, -1.10234535, -0.29102205]]),\n",
       "  array([1., 1., 1., 1., 1.])],\n",
       " [array([40.64405414, 40.73523553, 40.48779979, 39.86113031, 39.17953377]),\n",
       "  array([[ 1.08897093, -0.567808  ,  1.62966603, -1.2321259 , -2.0567455 ],\n",
       "         [ 0.28525642, -1.10818783,  1.51996792, -0.95454311, -0.46905331],\n",
       "         [ 0.08046122,  0.61737773,  0.8035759 ,  0.07691911,  0.20903837],\n",
       "         [-0.09427171, -1.0919443 ,  0.3894021 , -1.35922876, -0.14911038],\n",
       "         [ 2.21021305, -0.09712267,  1.52173519, -2.20674981,  0.12469352]]),\n",
       "  array([1., 1., 1., 1., 1.])]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_states = [[np.random.randn(5)+i*10,np.random.randn(5,5),np.ones(5)] for i in range(1,5)]\n",
    "fake_rewards = [1,2,3,4]\n",
    "fake_dones =[0,0,0,1]\n",
    "fake_actions = [10,20,30,40]\n",
    "fake_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from agents.memory import CustomerSequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_buffer = CustomerSequentialMemory(limit=5000, window_length=1)\n",
    "for obs,a, r, temin in zip(training_data['state'],training_data['action'], training_data['reward'], training_data['done']):\n",
    "    if isinstance(a,np.ndarray):\n",
    "        memory_buffer.append(obs,a,r,temin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory_buffer = CustomerSequentialMemory(limit=5000, window_length=1)\n",
    "# for obs,a, r, temin in zip(fake_states,fake_actions,fake_rewards,fake_dones):\n",
    "\n",
    "#     memory_buffer.append(obs,a,r,temin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_experience = memory_buffer.sample(1)\n",
    "\n",
    "state0_batch = []\n",
    "reward_batch = []\n",
    "action_batch = []\n",
    "terminal1_batch = []\n",
    "state1_batch = []\n",
    "for e in batch_experience:\n",
    "    state0_batch.append(e.state0)\n",
    "    state1_batch.append(e.state1)\n",
    "    reward_batch.append(e.reward)\n",
    "    action_batch.append(e.action)\n",
    "    terminal1_batch.append(0. if e.terminal1 else 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Experience(state0=[(array([[470.61819252,  62.71      ,   4.5906919 ,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [456.78061509,  62.71      ,   4.62387143,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [389.1536841 ,  62.71      ,   4.09758905,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [352.81553793,  62.71      ,   4.07771398,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [408.71363284,  62.71      ,   4.56308624,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [332.53946644,  62.71      ,   3.92507733,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [374.94099262,  65.91      ,   4.84403246,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [406.32899424,  65.91      ,   5.52544358,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [356.28252627,  65.91      ,   4.76845737,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [304.75137423,  62.71      ,   4.21603813,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [252.59691555,  62.71      ,   4.91107522,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [216.60607904,  62.71      ,   4.00110236,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [177.19390883,  65.91      ,   4.8736525 ,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [200.87602273,  65.91      ,   5.47357632,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [137.73026508,  62.71      ,   3.83243395,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [159.28812325,  65.91      ,   4.67728468,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [155.01454242,  69.11      ,   4.73950599,   0.        ,\n",
       "           0.        ,   1.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [144.01410739,  65.91      ,   4.96625225,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [ 94.18739967,  62.71      ,   4.80659611,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [ 63.65250996,  65.91      ,   4.31512242,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [262.11555503,   6.33444497,   3.12333033,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [234.56582666,  33.88417334,   3.11836102,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [163.6696726 ,  62.71      ,   3.91382873,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [190.54454549,  62.71      ,   3.93933849,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [150.3423676 ,  62.71      ,   3.87493063,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [124.50236501,  62.71      ,   3.73880765,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [ 82.32764702,  65.91      ,   5.16548358,   0.        ,\n",
       "           1.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [ 54.35614172,  62.71      ,   4.67877996,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [ 24.85477849,  69.11      ,   4.69107881,   0.        ,\n",
       "           0.        ,   1.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [ 17.57061146,  65.91      ,   5.3747364 ,   0.        ,\n",
       "           1.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [374.52243247,  62.71      ,   4.10360121,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [321.634986  ,  62.71      ,   3.91917637,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [283.24637244,  62.71      ,   4.48059087,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [230.18886293,  62.71      ,   4.09760544,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [176.96852044,  62.71      ,   3.92824229,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [203.11490711,  62.71      ,   3.95881732,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [110.4295616 ,  62.71      ,   4.163626  ,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [ 68.30071515,  62.71      ,   4.4812162 ,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [ 36.19179528,  62.71      ,   4.53929522,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [ 19.8314787 ,  62.71      ,   3.77275684,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ]]), array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 1., 1.],\n",
       "        [0., 0., 0., ..., 1., 1., 1.],\n",
       "        [0., 0., 0., ..., 1., 1., 1.]]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1.]))], action=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]), reward=0, state1=[[(array([[470.98728414,  62.71      ,   4.5906919 ,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [457.15235324,  62.71      ,   4.62360878,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [389.51329139,  62.71      ,   4.09878932,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [353.17329891,  62.71      ,   4.07774517,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [409.16994185,  62.71      ,   4.56309011,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [332.8838524 ,  62.71      ,   3.92529733,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [375.36601281,  65.91      ,   4.84436304,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [406.8815386 ,  65.91      ,   5.52544358,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [356.70090939,  65.91      ,   4.76871393,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [305.12116844,  62.71      ,   4.21489955,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [253.02776736,  62.71      ,   4.91083162,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [217.00629996,  62.71      ,   4.00220921,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [177.66937057,  65.91      ,   4.87478078,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [201.42338009,  65.91      ,   5.47357361,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [138.10417547,  62.71      ,   3.83360218,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [159.74444021,  65.91      ,   4.67849457,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [155.47681014,  69.11      ,   4.73950599,   0.        ,\n",
       "           0.        ,   1.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [144.49805544,  65.91      ,   4.96178861,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [ 94.6554952 ,  62.71      ,   4.799257  ,   1.        ,\n",
       "           0.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [ 64.07369207,  65.91      ,   4.31826641,   0.        ,\n",
       "           1.        ,   0.        ,   1.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [262.2843398 ,   6.1656602 ,   3.12333033,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [234.7343429 ,  33.7156571 ,   3.11836127,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [164.05143577,  62.71      ,   3.9141146 ,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [190.92883585,  62.71      ,   3.94002521,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [150.72038027,  62.71      ,   3.87566178,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [124.86719608,  62.71      ,   3.74051433,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [ 82.83145899,  65.91      ,   5.16544791,   0.        ,\n",
       "           1.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [ 54.81204458,  62.71      ,   4.67424885,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [ 25.31232564,  69.11      ,   4.69110724,   0.        ,\n",
       "           0.        ,   1.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [ 18.09571046,  65.91      ,   5.38369817,   0.        ,\n",
       "           1.        ,   0.        ,   0.        ,   1.        ,\n",
       "           0.        ],\n",
       "        [374.8824635 ,  62.71      ,   4.10361924,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [321.97885618,  62.71      ,   3.91941841,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [283.63943699,  62.71      ,   4.480134  ,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [230.54843538,  62.71      ,   4.09839229,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [177.35168329,  62.71      ,   3.92846509,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [203.51088538,  62.71      ,   3.95978269,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [110.83501609,  62.71      ,   4.15701528,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [ 68.73781273,  62.71      ,   4.48144343,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [ 36.63458314,  62.71      ,   4.53978432,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ],\n",
       "        [ 20.19984257,  62.71      ,   3.7767352 ,   1.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           1.        ]]), array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 1., 1.],\n",
       "        [0., 0., 0., ..., 1., 1., 1.],\n",
       "        [0., 0., 0., ..., 1., 1., 1.]])), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1.])]], terminal1=False)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from rl.processors import Processor\n",
    "class Jiqian_MultiInputProcessor(Processor):\n",
    "    \"\"\"\n",
    "    The multi input preprocessor for the model\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_inputs):\n",
    "            self.nb_inputs = nb_inputs\n",
    "\n",
    "    def process_state_batch(self, state_batch):\n",
    "        input_batches = [[] for x in range(self.nb_inputs)]\n",
    "        # print((state_batch))\n",
    "        for state in state_batch:\n",
    "            for observation in state:\n",
    "                assert len(observation) == self.nb_inputs\n",
    "                for idx,s in enumerate(observation):\n",
    "                    input_batches[idx].append(s)\n",
    "\n",
    "        rt = [np.array(x) for x in input_batches]\n",
    "\n",
    "        return rt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi_input_processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7453482089ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_input_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_state_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate0_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'multi_input_processor' is not defined"
     ]
    }
   ],
   "source": [
    "processed = multi_input_processor.process_state_batch(state0_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_in (InputLayer)               [(None, 40, 9)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A_in (InputLayer)               [(None, 40, 40)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn1 (GraphConv)                (None, 40, 32)       320         X_in[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gcn2 (GraphConv)                (None, 40, 32)       1056        gcn1[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "policy_1 (Dense)                (None, 40, 32)       1056        gcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "policy_2 (Dense)                (None, 40, 16)       528         policy_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "policy_3 (Dense)                (None, 40, 3)        51          policy_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expend_dim (Reshape)            (None, 40, 1)        0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "filter (Multiply)               (None, 40, 3)        0           policy_3[0][0]                   \n",
      "                                                                 expend_dim[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,011\n",
      "Trainable params: 3,011\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class GraphicQNetworkKeras():\n",
    "    def __init__(self, N,F, obs_space, action_space, num_outputs=3, model_config=None, name='graphic_policy_keras'):\n",
    "        self.obs_space = obs_space\n",
    "        self.action_space = action_space\n",
    "        self.num_outputs = num_outputs\n",
    "        self.name = name\n",
    "        self.base_model = self.build_model(N,F,num_outputs)\n",
    "\n",
    "    def build_model(self,N,F,num_outputs):\n",
    "        X_in = Input(shape=(N,F), name='X_in')\n",
    "        A_in = Input(shape=(N,N), name='A_in')\n",
    "        RL_indice = Input(shape=(N), name='mask')\n",
    "\n",
    "        ### Graphic convolution\n",
    "\n",
    "        x = GraphConv(32, activation='relu',name='gcn1')([X_in, A_in])\n",
    "        x = GraphConv(32, activation='relu',name='gcn2')([x, A_in])\n",
    "\n",
    "        ### Policy network\n",
    "        x1 = Dense(32,activation='relu',name='policy_1')(x)\n",
    "        x2 = Dense(16,activation='relu',name='policy_2')(x1)\n",
    "\n",
    "        ###  Action and filter\n",
    "        x3 = Dense(num_outputs, activation='linear',name='policy_3')(x2)\n",
    "        mask = Reshape((N,1),name='expend_dim')(RL_indice)\n",
    "        qout = Multiply(name='filter')([x3,mask])\n",
    "\n",
    "        model = Model(inputs = [X_in,A_in,RL_indice], outputs=[qout])\n",
    "        print(model.summary())\n",
    "        return model\n",
    "rl_model = GraphicQNetworkKeras(N,F, obs_space, act_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rl_model.base_model.predict(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_true = np.ones([10,40,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import Huber\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.policy import Policy\n",
    "class greedy_q_policy(Policy):\n",
    "    def select_action(self,q_vals):\n",
    "        action = None\n",
    "        mask = np.any(q_vals, axis=1)\n",
    "        if mask.sum() > 0:\n",
    "            action = q_vals[mask,:].argmax(1)\n",
    "        return action\n",
    "\n",
    "class random_obs_policy(Policy):\n",
    "    def select_action(self,observation):\n",
    "        action = None\n",
    "        _,_,mask = observation\n",
    "        num_agent = mask.sum().astype(int)\n",
    "        if num_agent>0:\n",
    "            action = np.random.choice(np.arange(3),num_agent)\n",
    "        return action\n",
    "\n",
    "class eps_greedy_q_policy(Policy):\n",
    "    def __init__(self, eps=.1):\n",
    "        super(eps_greedy_q_policy, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def select_action(self,q_vals):\n",
    "        action = None\n",
    "        mask = np.any(q_vals, axis=1)\n",
    "        num_agent = mask.sum().astype(int)\n",
    "        if num_agent>0:\n",
    "            if np.random.uniform() < self.eps:  # choose random action\n",
    "                action = np.random.choice(np.arange(3),num_agent)\n",
    "            else:\n",
    "                action = q_vals[mask,:].argmax(1)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.memory import CustomerSequentialMemory\n",
    "memory_buffer = CustomerSequentialMemory(limit=5000, window_length=1)\n",
    "\n",
    "\n",
    "for obs,a, r, temin in zip(training_data['state'],training_data['action'], training_data['reward'], training_data['done']):\n",
    "    if isinstance(a,np.ndarray):\n",
    "        memory_buffer.append(obs,a,r,temin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_policy = greedy_q_policy()\n",
    "start_policy = random_obs_policy()\n",
    "train_policy = eps_greedy_q_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ragged'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-26971ca110db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmy_dqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/OneDrive - purdue.edu/work3/codes/agents/dqn.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, metrics)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# We never train the target model, hence we can set the optimizer and loss arbitrarily.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_model_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/rl/util.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, custom_objects)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    591\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1029\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1030\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m                                         list(custom_objects.items())))\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flow/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ragged'"
     ]
    }
   ],
   "source": [
    "from agents.dqn import DQNAgent\n",
    "multi_input_processor = Jiqian_MultiInputProcessor(3)\n",
    "my_dqn = DQNAgent(processor= multi_input_processor,\n",
    "                  model = rl_model.base_model, \n",
    "                  policy = train_policy,\n",
    "                  test_policy=test_policy,\n",
    "                  nb_total_agents = 40, \n",
    "                  nb_actions = 3, \n",
    "                  memory = memory_buffer,\n",
    "                  nb_steps_warmup=10)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "my_dqn.compile(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tf.keras.callbacks.CallbackList\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.callbacks' has no attribute 'CallbackList'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6eb40a0f6bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallbackList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.callbacks' has no attribute 'CallbackList'"
     ]
    }
   ],
   "source": [
    "tf.keras.callbacks.CallbackList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
