{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.arange(10).reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  2.82842712,  5.65685425,  8.48528137, 11.3137085 ],\n",
       "       [ 2.82842712,  0.        ,  2.82842712,  5.65685425,  8.48528137],\n",
       "       [ 5.65685425,  2.82842712,  0.        ,  2.82842712,  5.65685425],\n",
       "       [ 8.48528137,  5.65685425,  2.82842712,  0.        ,  2.82842712],\n",
       "       [11.3137085 ,  8.48528137,  5.65685425,  2.82842712,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix = euclidean_distances(positions)\n",
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix[dist_matrix<5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  5.65685425,  8.48528137, 11.3137085 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  5.65685425,  8.48528137],\n",
       "       [ 5.65685425,  0.        ,  0.        ,  0.        ,  5.65685425],\n",
       "       [ 8.48528137,  5.65685425,  0.        ,  0.        ,  0.        ],\n",
       "       [11.3137085 ,  8.48528137,  5.65685425,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import GraphConv\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.backend import gather, squeeze\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_in (InputLayer)               [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A_in (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn1 (GraphConv)                (None, 32)           320         X_in[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gcn2 (GraphConv)                (None, 32)           1056        gcn1[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "slice (Lambda)                  (1, None, 32)        0           gcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "squeeze (Lambda)                (None, 32)           0           slice[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "policy_1 (Dense)                (None, 32)           1056        squeeze[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "policy_2 (Dense)                (None, 16)           528         policy_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "RL_indice (InputLayer)          [(1, None)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "policy_3 (Dense)                (None, 3)            51          policy_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,011\n",
      "Trainable params: 3,011\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class GraphicEncoder():\n",
    "    def __init__(self, F):\n",
    "        self.model = self.build_model(F)\n",
    "\n",
    "    def build_model(self,F):\n",
    "        X_in = Input(shape=(F,), name='X_in')\n",
    "        A_in = Input(shape=(None,), name='A_in')\n",
    "        RL_indice = Input(shape=(None,),batch_size = 1, name='RL_indice',dtype='int32')\n",
    "\n",
    "        \n",
    "        ### Graphic convolution\n",
    "        \n",
    "        x = GraphConv(32, activation='relu',name='gcn1')([X_in, A_in])\n",
    "        x = GraphConv(32, activation='relu',name='gcn2')([x, A_in])\n",
    "        x = Lambda(lambda x: gather(x,RL_indice),name='slice')(x)\n",
    "        \n",
    "        x = Lambda(lambda x: squeeze(x,0),name='squeeze')(x)\n",
    "        \n",
    "        ### Policy network\n",
    "        \n",
    "        x = Dense(32,activation='relu',name='policy_1')(x)\n",
    "        x = Dense(16,activation='relu',name='policy_2')(x)\n",
    "        x = Dense(3, activation='relu',name='policy_3')(x)\n",
    "        \n",
    "        \n",
    "        model = Model(inputs = [X_in,A_in,RL_indice], outputs=x)\n",
    "        print(model.summary())\n",
    "        return model\n",
    "    \n",
    "    \n",
    "feature_size = 9\n",
    "rl_model = GraphicEncoder(feature_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces.box import Box\n",
    "from gym.spaces import Discrete\n",
    "from gym.spaces.dict import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0519 21:04:10.313662 4385142208 deprecation.py:323] From /anaconda3/envs/flow/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.models.tf.tf_modelv2 import TFModelV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 9\n",
    "N = 40\n",
    "\n",
    "states = Box(low=-np.inf, high=np.inf, shape=(N,F), dtype=np.float32)\n",
    "adjacency = Box(low=0, high=1, shape = (N,N), dtype=np.int32)\n",
    "mask = Box(low=0, high=1, shape = (N,), dtype=np.int32)\n",
    "\n",
    "obs_space = Dict({'states':states,'adjacency':adjacency,'mask':mask})\n",
    "act_space = Box(low=0, high=1, shape = (N,), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0519 21:04:10.664104 4385142208 deprecation.py:506] From /anaconda3/envs/flow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_in (InputLayer)               [(None, 40, 9)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A_in (InputLayer)               [(None, 40, 40)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn1 (GraphConv)                (None, 40, 32)       320         X_in[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gcn2 (GraphConv)                (None, 40, 32)       1056        gcn1[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "policy_1 (Dense)                (None, 40, 32)       1056        gcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "policy_2 (Dense)                (None, 40, 16)       528         policy_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "policy_3 (Dense)                (None, 40, 3)        51          policy_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expend_dim (Reshape)            (None, 40, 1)        0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 640)          0           policy_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "filter (Multiply)               (None, 40, 3)        0           policy_3[0][0]                   \n",
      "                                                                 expend_dim[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "value_out (Dense)               (None, 1)            641         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,652\n",
      "Trainable params: 3,652\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from spektral.layers import GraphConv\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Multiply, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "class GraphicPolicy(TFModelV2):\n",
    "    def __init__(self, N,F, obs_space, action_space, num_outputs=3, model_config=None, name='graphic_policy'):\n",
    "        super(GraphicPolicy,self).__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "        self.base_model = self.build_model(N,F,num_outputs)\n",
    "        self.register_variables(self.base_model.variables)\n",
    "        \n",
    "    def build_model(self,N,F,num_outputs):\n",
    "        X_in = Input(shape=(N,F), name='X_in')\n",
    "        A_in = Input(shape=(N,N), name='A_in')\n",
    "        RL_indice = Input(shape=(N), name='mask')\n",
    "        \n",
    "        ### Graphic convolution\n",
    "        \n",
    "        x = GraphConv(32, activation='relu',name='gcn1')([X_in, A_in])\n",
    "        x = GraphConv(32, activation='relu',name='gcn2')([x, A_in])\n",
    "\n",
    "        \n",
    "        ### Policy network\n",
    "        \n",
    "        x1 = Dense(32,activation='relu',name='policy_1')(x)\n",
    "        x2 = Dense(16,activation='relu',name='policy_2')(x1)\n",
    "        \n",
    "    \n",
    "        ###  Action and filter\n",
    "        x3 = Dense(num_outputs, activation='relu',name='policy_3')(x2)\n",
    "        mask = Reshape((N,1),name='expend_dim')(RL_indice)\n",
    "        out = Multiply(name='filter')([x3,mask])\n",
    "        \n",
    "        \n",
    "        #### Value out\n",
    "        x2 = Flatten(name='flatten')(x2)\n",
    "        value = Dense(1,activation='linear',name='value_out')(x2)\n",
    "        \n",
    "\n",
    "        model = Model(inputs = [X_in,A_in,RL_indice], outputs=[out,value])\n",
    "        print(model.summary())\n",
    "        return model\n",
    "    \n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dic['obs']\n",
    "        model_out, self._value_out = self.base_model({X_in:obs['states'],A_in:obs['adjacency'],RL_indice:obs['mask']})        \n",
    "        return model_out,state\n",
    "        \n",
    "    def value_function(self):\n",
    "        return tf.reshape(self._value_out, [-1])\n",
    "    \n",
    "model_config = {}\n",
    "rl_model = GraphicPolicy(N,F, obs_space, act_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for the model + agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_data.pkl','rb') as f:\n",
    "    training_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'action', 'reward', 'done'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2292"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['state'][300][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_buffer = SequentialMemory(limit=5000, window_length=1)\n",
    "for obs,a, r, temin in zip(training_data['state'],training_data['action'], training_data['reward'], training_data['done']):\n",
    "    if isinstance(a,np.ndarray):\n",
    "        memory_buffer.append(obs,a,r,temin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_experience = memory_buffer.sample(32)\n",
    "\n",
    "state0_batch = []\n",
    "reward_batch = []\n",
    "action_batch = []\n",
    "terminal1_batch = []\n",
    "state1_batch = []\n",
    "for e in batch_experience:\n",
    "    state0_batch.append(e.state0)\n",
    "    state1_batch.append(e.state1)\n",
    "    reward_batch.append(e.reward)\n",
    "    action_batch.append(e.action)\n",
    "    terminal1_batch.append(0. if e.terminal1 else 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from rl.processors import Processor\n",
    "class Jiqian_MultiInputProcessor(Processor):\n",
    "    \"\"\"\n",
    "    The multi input preprocessor for the model\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_inputs):\n",
    "            self.nb_inputs = nb_inputs\n",
    "\n",
    "    def process_state_batch(self, state_batch):\n",
    "        input_batches = [[] for x in range(self.nb_inputs)]\n",
    "        # print((state_batch))\n",
    "        for state in state_batch:\n",
    "            for observation in state:\n",
    "                assert len(observation) == self.nb_inputs\n",
    "                for idx,s in enumerate(observation):\n",
    "                    input_batches[idx].append(s)\n",
    "\n",
    "        rt = [np.array(x) for x in input_batches]\n",
    "\n",
    "        return rt\n",
    "    \n",
    "multi_input_processor = Jiqian_MultiInputProcessor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = multi_input_processor.process_state_batch(state0_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_in (InputLayer)               [(None, 40, 9)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A_in (InputLayer)               [(None, 40, 40)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn1 (GraphConv)                (None, 40, 32)       320         X_in[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gcn2 (GraphConv)                (None, 40, 32)       1056        gcn1[0][0]                       \n",
      "                                                                 A_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "policy_1 (Dense)                (None, 40, 32)       1056        gcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "policy_2 (Dense)                (None, 40, 16)       528         policy_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "policy_3 (Dense)                (None, 40, 3)        51          policy_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expend_dim (Reshape)            (None, 40, 1)        0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "filter (Multiply)               (None, 40, 3)        0           policy_3[0][0]                   \n",
      "                                                                 expend_dim[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,011\n",
      "Trainable params: 3,011\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class GraphicQNetworkKeras():\n",
    "    def __init__(self, N,F, obs_space, action_space, num_outputs=3, model_config=None, name='graphic_policy_keras'):\n",
    "        self.obs_space = obs_space\n",
    "        self.action_space = action_space\n",
    "        self.num_outputs = num_outputs\n",
    "        self.name = name\n",
    "        self.base_model = self.build_model(N,F,num_outputs)\n",
    "\n",
    "    def build_model(self,N,F,num_outputs):\n",
    "        X_in = Input(shape=(N,F), name='X_in')\n",
    "        A_in = Input(shape=(N,N), name='A_in')\n",
    "        RL_indice = Input(shape=(N), name='mask')\n",
    "\n",
    "        ### Graphic convolution\n",
    "\n",
    "        x = GraphConv(32, activation='relu',name='gcn1')([X_in, A_in])\n",
    "        x = GraphConv(32, activation='relu',name='gcn2')([x, A_in])\n",
    "\n",
    "        ### Policy network\n",
    "        x1 = Dense(32,activation='relu',name='policy_1')(x)\n",
    "        x2 = Dense(16,activation='relu',name='policy_2')(x1)\n",
    "\n",
    "        ###  Action and filter\n",
    "        x3 = Dense(num_outputs, activation='softmax',name='policy_3')(x2)\n",
    "        mask = Reshape((N,1),name='expend_dim')(RL_indice)\n",
    "        qout = Multiply(name='filter')([x3,mask])\n",
    "\n",
    "        model = Model(inputs = [X_in,A_in,RL_indice], outputs=[qout])\n",
    "        print(model.summary())\n",
    "        return model\n",
    "rl_model = GraphicQNetworkKeras(N,F, obs_space, act_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rl_model.base_model.predict(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 40, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[2][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vals = predicted[0]\n",
    "q_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.any(q_vals, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 0, 2, 0, 2, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = processed[2][0]\n",
    "\n",
    "num_agent = mask.sum().astype(int)\n",
    "np.random.choice(np.array([0,1,2]),num_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.policy import Policy\n",
    "class greedy_q_policy(Policy):\n",
    "    def select_action(self,q_vals):\n",
    "        action = None\n",
    "        mask = np.any(q_vals, axis=1)\n",
    "        if mask.sum() > 0:\n",
    "            action = q_vals[mask,:].argmax(1)\n",
    "        return action\n",
    "\n",
    "class random_obs_policy(Policy):\n",
    "    def select_action(self,observation):\n",
    "        action = None\n",
    "        _,_,mask = observation\n",
    "        num_agent = mask.sum().astype(int)\n",
    "        if num_agent>0:\n",
    "            action = np.random.choice(np.arange(3),num_agent)\n",
    "        return action\n",
    "\n",
    "class eps_greedy_q_policy(Policy):\n",
    "    def __init__(self, eps=.1):\n",
    "        super(eps_greedy_q_policy, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def select_action(self,q_vals):\n",
    "        action = None\n",
    "        mask = np.any(q_vals, axis=1)\n",
    "        num_agent = mask.sum().astype(int)\n",
    "        if num_agent>0:\n",
    "            if np.random.uniform() < self.eps:  # choose random action\n",
    "                action = np.random.choice(np.arange(3),num_agent)\n",
    "            else:\n",
    "                action = q_vals[mask,:].argmax(1)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = eps_greedy_q_policy(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.select_action(q_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.dqn import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
